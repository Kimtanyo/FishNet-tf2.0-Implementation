{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpQPrajJ6ilf"
   },
   "source": [
    "# Colab Loading..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXRMjWit6iYq",
    "outputId": "1e66d1f2-8bcc-4f4d-c9ec-184169077fa0"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVXucehQ6h7C",
    "outputId": "05a1d3cd-e59c-4b9d-9258-09c9a318b3fd"
   },
   "outputs": [],
   "source": [
    "#!ls /gdrive/MyDrive/E4040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MV0_kqh5q-lU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cf8KZTiOMJku"
   },
   "outputs": [],
   "source": [
    "# !cat /gdrive/MyDrive/E4040/model_tf2/fishnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOoAD-Uc8d9r"
   },
   "outputs": [],
   "source": [
    "#import os, sys\n",
    "#sys.path.append('/gdrive/MyDrive/E4040')\n",
    "#os.chdir('/gdrive/MyDrive/E4040')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyrVh4shMKi5",
    "outputId": "4fde23bb-f07f-4798-a48f-f3fb811841ba"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-jmVvIC7mkp"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "924ecfeb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import model_tf2.net_factory as netf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1bfdbc2b",
    "outputId": "96a404c1-035c-488a-b929-c893296027ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ddda512f"
   },
   "outputs": [],
   "source": [
    "#init some global variables\n",
    "num_train_files = 128 #number of training tfrecords\n",
    "num_val_files = 64 #number of testing tfrecords\n",
    "buffer_size = 100\n",
    "num_channels = 3\n",
    "img_size = 64\n",
    "num_classes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a6a95c26"
   },
   "outputs": [],
   "source": [
    "def get_filenames(is_training):\n",
    "    \"\"\"\n",
    "    input: is_training \n",
    "    output: a list of training/validation file names\n",
    "    \"\"\"\n",
    "    filenames = []\n",
    "    if is_training:\n",
    "        for i in range(num_train_files):\n",
    "            filename = \"data/tf_records/train/\" + 'train-%05d-of-00128' % i\n",
    "            filenames.append(filename)\n",
    "    else:\n",
    "        for i in range(num_val_files):\n",
    "            filename = \"data/tf_records/val/\" + 'val-%05d-of-00064' % i\n",
    "            filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "def parse_record(record):\n",
    "    \"\"\"\n",
    "    input: a tfrecord\n",
    "    output: parsed tfrecord based on features\n",
    "    \"\"\"\n",
    "    name_to_features = {\n",
    "        'image/class/label': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/class/synset': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    return tf.io.parse_single_example(record, name_to_features)\n",
    "\n",
    "def preprocess_data(is_training):\n",
    "    \"\"\"\n",
    "    input: bool is_training\n",
    "    output: training/val X,y tuple ready to feed into models\n",
    "    \"\"\"\n",
    "    #init X and y list\n",
    "    X = []\n",
    "    y = []\n",
    "    #get all filenames\n",
    "    filenames = get_filenames(is_training)\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    parsed_dataset = raw_dataset.map(parse_record)\n",
    "    # num_samples = None\n",
    "    # if is_training:\n",
    "    #     num_samples = num_train_files*buffer_size\n",
    "    # else:\n",
    "    #     num_samples = num_val_files*buffer_size\n",
    "    # #get image and label from each parsed sample\n",
    "    # for parsed in parsed_dataset.take(num_samples):\n",
    "    #     image = tf.io.decode_jpeg(parsed['image/encoded'], channels=3)\n",
    "    #     label = parsed[\"image/class/label\"]\n",
    "    #     X.append(image)\n",
    "    #     y.append(label-1)\n",
    "    for parsed in parsed_dataset:\n",
    "        image = tf.io.decode_jpeg(parsed['image/encoded'], channels=3)\n",
    "        label = parsed[\"image/class/label\"]\n",
    "        X.append(image)\n",
    "        y.append(label-1)\n",
    "    #reshape X to num_samples * num_channel * height * width \n",
    "    #cast to float 32\n",
    "    #X = tf.image.convert_image_dtype(X, dtype=tf.float32, saturate=False)\n",
    "    X = tf.reshape(tf.stack(X), (-1, num_channels, img_size, img_size))\n",
    "    X = X/255\n",
    "    #X = tf.cast(tf.reshape(tf.stack(X), \n",
    "                   #(num_samples, num_channels, img_size, img_size)),\n",
    "                #tf.float32)\n",
    "\n",
    "    X = tf.cast(tf.transpose(tf.reshape(tf.stack(X), \n",
    "                                        (-1, img_size, img_size, num_channels)),\n",
    "                             [0,3,1,2]),\n",
    "                tf.float32)\n",
    "\n",
    "    y = tf.stack(y)\n",
    "    #y = tf.cast(tf.stack(y), tf.float32)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7Q1j5JO_w9KO"
   },
   "outputs": [],
   "source": [
    "def format_image(image):\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.transpose(tf.reshape(image,(img_size, img_size, num_channels)), [2,0,1])\n",
    "    image /= 255.\n",
    "    return image\n",
    "\n",
    "def read_parsed(parsed):\n",
    "    image = format_image(parsed['image/encoded'])\n",
    "    label = parsed['image/class/label'] - 1\n",
    "    \n",
    "    return image, label\n",
    "    \n",
    "def get_dataset(filenames, batch_size=32):\n",
    "    \n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "    parsed_dataset = raw_dataset.map(parse_record)\n",
    "    dataset = parsed_dataset.map(read_parsed)\n",
    "    \n",
    "    dataset = dataset.shuffle(84)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2b01eb12"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    #create a fishnet model\n",
    "    #model = netf.myfishnet()\n",
    "    model = netf.fishnet150()\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train(model, trained_times):\n",
    "    \"\"\"\n",
    "    input: model - either a new fishnet model or a trained model with weights loaded\n",
    "           int trained_times - how many time the model has been trained before. The input of an untrained model is 0\n",
    "    output: model\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size=256\n",
    "    epochs=5\n",
    "\n",
    "    train_files = get_filenames(is_training=True)\n",
    "    val_files = get_filenames(is_training=False)\n",
    "\n",
    "    train_ds = get_dataset(train_files, batch_size=batch_size)\n",
    "    val_ds = get_dataset(val_files, batch_size=batch_size)\n",
    "\n",
    "    #lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "    #save checkpoints for quicker access later\n",
    "    checkpoint_path = \"training_{}/cp.ckpt\".format(trained_times)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True,\n",
    "                                                     verbose=1)\n",
    "    #train model with cp_callback\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=epochs, steps_per_epoch=100, validation_steps=50,\n",
    "              callbacks=[cp_callback])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5009c3ac",
    "outputId": "79e93e69-64c4-4f54-c013-6577ff93e53d",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecbm4040/envTF24/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 62s 565ms/step - loss: 5.2119 - accuracy: 0.0167 - val_loss: 5.3899 - val_accuracy: 0.0050\n",
      "\n",
      "Epoch 00001: saving model to training_0/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 70s 698ms/step - loss: 4.8470 - accuracy: 0.0490 - val_loss: 5.5356 - val_accuracy: 0.0054\n",
      "\n",
      "Epoch 00002: saving model to training_0/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 94s 945ms/step - loss: 4.5906 - accuracy: 0.0645 - val_loss: 5.8164 - val_accuracy: 0.0051\n",
      "\n",
      "Epoch 00003: saving model to training_0/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 132s 1s/step - loss: 4.4152 - accuracy: 0.0909 - val_loss: 6.0987 - val_accuracy: 0.0049\n",
      "\n",
      "Epoch 00004: saving model to training_0/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 176s 2s/step - loss: 4.2935 - accuracy: 0.1017 - val_loss: 6.0457 - val_accuracy: 0.0050\n",
      "\n",
      "Epoch 00005: saving model to training_0/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<model_tf2.fishnet.FishNet at 0x7fee6c082a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#epoch1-5\n",
    "model0 = create_model()\n",
    "train(model0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.index', 'cp.ckpt.data-00000-of-00001', 'checkpoint']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out saved checkpoints\n",
    "checkpoint_path = \"training_0/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fede802fcc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a model \n",
    "model1 = create_model()\n",
    "#load trained weights\n",
    "model1.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 57s 555ms/step - loss: 4.1019 - accuracy: 0.1273 - val_loss: 5.9649 - val_accuracy: 0.0057\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 70s 699ms/step - loss: 4.0827 - accuracy: 0.1292 - val_loss: 5.9518 - val_accuracy: 0.0096\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 95s 952ms/step - loss: 3.9558 - accuracy: 0.1471 - val_loss: 5.7842 - val_accuracy: 0.0110\n",
      "\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 130s 1s/step - loss: 3.8937 - accuracy: 0.1587 - val_loss: 6.1444 - val_accuracy: 0.0215\n",
      "\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 178s 2s/step - loss: 3.8241 - accuracy: 0.1663 - val_loss: 5.4316 - val_accuracy: 0.0347\n",
      "\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "#epoch 6-10\n",
    "model1 = train(model1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ud2jWu-C-N4_",
    "outputId": "f21c6e79-5b30-417a-f687-19602c91a84e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.index', 'cp.ckpt.data-00000-of-00001', 'checkpoint']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out saved checkpoints\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ACngegMYNdAk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fedd6772358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a model \n",
    "model2 = create_model()\n",
    "#load trained weights\n",
    "model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 57s 554ms/step - loss: 3.5261 - accuracy: 0.2082 - val_loss: 4.5875 - val_accuracy: 0.0760\n",
      "\n",
      "Epoch 00001: saving model to training_2/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 3.7187 - accuracy: 0.1885 - val_loss: 4.4441 - val_accuracy: 0.0948\n",
      "\n",
      "Epoch 00002: saving model to training_2/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 94s 947ms/step - loss: 3.6157 - accuracy: 0.1983 - val_loss: 4.3624 - val_accuracy: 0.1050\n",
      "\n",
      "Epoch 00003: saving model to training_2/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 132s 1s/step - loss: 3.5796 - accuracy: 0.2056 - val_loss: 4.0926 - val_accuracy: 0.1342\n",
      "\n",
      "Epoch 00004: saving model to training_2/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 179s 2s/step - loss: 3.4281 - accuracy: 0.2275 - val_loss: 3.8737 - val_accuracy: 0.1602\n",
      "\n",
      "Epoch 00005: saving model to training_2/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "#epoch 11-15\n",
    "model2 = train(model2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 56s 553ms/step - loss: 3.2653 - accuracy: 0.2537 - val_loss: 3.9454 - val_accuracy: 0.1548\n",
      "\n",
      "Epoch 00001: saving model to training_3/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 69s 695ms/step - loss: 3.4542 - accuracy: 0.2276 - val_loss: 3.7600 - val_accuracy: 0.1820\n",
      "\n",
      "Epoch 00002: saving model to training_3/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 95s 949ms/step - loss: 3.4223 - accuracy: 0.2323 - val_loss: 3.9903 - val_accuracy: 0.1533\n",
      "\n",
      "Epoch 00003: saving model to training_3/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 131s 1s/step - loss: 3.4007 - accuracy: 0.2355 - val_loss: 3.6511 - val_accuracy: 0.1939\n",
      "\n",
      "Epoch 00004: saving model to training_3/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 181s 2s/step - loss: 3.2182 - accuracy: 0.2606 - val_loss: 3.7429 - val_accuracy: 0.1773\n",
      "\n",
      "Epoch 00005: saving model to training_3/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "#epoch 16-20\n",
    "#check out saved checkpoints\n",
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)\n",
    "#create a model \n",
    "model3 = create_model()\n",
    "#load trained weights\n",
    "model3.load_weights(checkpoint_path)\n",
    "model3 = train(model3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 56s 548ms/step - loss: 3.0522 - accuracy: 0.2920 - val_loss: 3.6765 - val_accuracy: 0.1958\n",
      "\n",
      "Epoch 00001: saving model to training_4/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 70s 701ms/step - loss: 3.2734 - accuracy: 0.2594 - val_loss: 3.6818 - val_accuracy: 0.1937\n",
      "\n",
      "Epoch 00002: saving model to training_4/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 95s 955ms/step - loss: 3.2867 - accuracy: 0.2519 - val_loss: 3.7313 - val_accuracy: 0.1944\n",
      "\n",
      "Epoch 00003: saving model to training_4/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 132s 1s/step - loss: 3.2655 - accuracy: 0.2586 - val_loss: 3.6255 - val_accuracy: 0.2049\n",
      "\n",
      "Epoch 00004: saving model to training_4/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 179s 2s/step - loss: 3.0340 - accuracy: 0.2955 - val_loss: 3.8875 - val_accuracy: 0.1643\n",
      "\n",
      "Epoch 00005: saving model to training_4/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "#epoch 21-25\n",
    "#check out saved checkpoints\n",
    "num_five_epoch = 4\n",
    "checkpoint_path = \"training_{}/cp.ckpt\".format(num_five_epoch-1)\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)\n",
    "#create a model \n",
    "model4 = create_model()\n",
    "#load trained weights\n",
    "model4.load_weights(checkpoint_path)\n",
    "model4 = train(model4, num_five_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 58s 553ms/step - loss: 2.8770 - accuracy: 0.3214 - val_loss: 3.8648 - val_accuracy: 0.1706\n",
      "\n",
      "Epoch 00001: saving model to training_5/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 70s 705ms/step - loss: 3.1514 - accuracy: 0.2829 - val_loss: 3.7118 - val_accuracy: 0.1935\n",
      "\n",
      "Epoch 00002: saving model to training_5/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 96s 963ms/step - loss: 3.1888 - accuracy: 0.2685 - val_loss: 3.8090 - val_accuracy: 0.1921\n",
      "\n",
      "Epoch 00003: saving model to training_5/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 133s 1s/step - loss: 3.1613 - accuracy: 0.2789 - val_loss: 3.4988 - val_accuracy: 0.2297\n",
      "\n",
      "Epoch 00004: saving model to training_5/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 181s 2s/step - loss: 2.8696 - accuracy: 0.3263 - val_loss: 3.8364 - val_accuracy: 0.1766\n",
      "\n",
      "Epoch 00005: saving model to training_5/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "#epoch 26-30\n",
    "#check out saved checkpoints\n",
    "num_five_epoch = 5\n",
    "checkpoint_path = \"training_{}/cp.ckpt\".format(num_five_epoch-1)\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)\n",
    "#create a model \n",
    "model4 = create_model()\n",
    "#load trained weights\n",
    "model4.load_weights(checkpoint_path)\n",
    "model4 = train(model4, num_five_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 58s 565ms/step - loss: 2.7539 - accuracy: 0.3457 - val_loss: 3.8345 - val_accuracy: 0.1856\n",
      "\n",
      "Epoch 00001: saving model to training_6/cp.ckpt\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 70s 707ms/step - loss: 3.0510 - accuracy: 0.3023 - val_loss: 3.8819 - val_accuracy: 0.1738\n",
      "\n",
      "Epoch 00002: saving model to training_6/cp.ckpt\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 96s 964ms/step - loss: 3.1103 - accuracy: 0.2796 - val_loss: 3.7986 - val_accuracy: 0.1906\n",
      "\n",
      "Epoch 00003: saving model to training_6/cp.ckpt\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 133s 1s/step - loss: 3.0783 - accuracy: 0.2904 - val_loss: 3.5276 - val_accuracy: 0.2248\n",
      "\n",
      "Epoch 00004: saving model to training_6/cp.ckpt\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 182s 2s/step - loss: 2.7284 - accuracy: 0.3539 - val_loss: 4.1870 - val_accuracy: 0.1436\n",
      "\n",
      "Epoch 00005: saving model to training_6/cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "#epoch 31-35\n",
    "#check out saved checkpoints\n",
    "num_five_epoch = 6\n",
    "checkpoint_path = \"training_{}/cp.ckpt\".format(num_five_epoch-1)\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "os.listdir(checkpoint_dir)\n",
    "#create a model \n",
    "model4 = create_model()\n",
    "#load trained weights\n",
    "model4.load_weights(checkpoint_path)\n",
    "model4 = train(model4, num_five_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
